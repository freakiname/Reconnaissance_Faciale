# Real-Time Facial Recognition

A real-time facial recognition system using **Transfer Learning** with the **VGG19** model. The project captures faces via webcam, trains a classifier on custom identities, and performs live recognition using OpenCV and TensorFlow/Keras.

---

## Overview

- **Model:** VGG19 (pre-trained on ImageNet) with frozen convolutional layers and a custom classification head (Flatten → Dense(128, ReLU) → Dense(num_classes, Softmax)).
- **Face detection:** OpenCV Haar Cascade (`haarcascade_frontalface_default.xml`).
- **Input:** Images resized to **224×224** and preprocessed with VGG19’s `preprocess_input`.
- **Output:** Real-time prediction of person identity with confidence, displayed on the webcam feed.

---

## Project Structure

```
Reconnaissance_Faciale/
├── dataset/                    # Training images (one folder per person)
│   ├── Person1/
│   │   ├── 0.jpg
│   │   └── ...
│   └── Person2/
│       └── ...
├── model/
│   └── vgg19_face_model.h5     # Trained model (generated by training)
├── train_model.ipynb           # Training notebook (VGG19 transfer learning)
├── realtime_recognition.py     # Real-time recognition from webcam
├── save_script.py              # Capture face images for a new person
├── augment.py                  # Data augmentation for a person's folder
├── requirements.txt            # Python dependencies
└── README.md                   # This file
```

---

## Requirements

- Python 3.8+
- Webcam

Install dependencies:

```bash
pip install -r requirements.txt
```

Main packages: `tensorflow`, `keras`, `opencv-python`, `numpy`, `scikit-learn`, `matplotlib`, `Pillow`.

---

## Quick Start

### 1. Capture face images for a person

Capture 60 face images for one identity (images are saved under `dataset/<Name>/`):

```bash
python save_script.py NomPersonne
```

Example:

```bash
python save_script.py Amine
```

- Face the webcam; the script detects your face and saves crops.
- Press **Q** to stop early.
- Images are stored in `dataset/NomPersonne/` (e.g. `dataset/Amine/`).

### 2. (Optional) Augment data for a person

Increase the number of training images for one folder (e.g. to improve robustness):

```bash
python augment.py <folder_name>
```

Example:

```bash
python augment.py Amine
```

This adds augmented images (rotation, shift, zoom, flip, brightness) in the same folder. Default target is 30 augmented images per original image.

### 3. Train the model

1. Open `train_model.ipynb` in Jupyter.
2. Ensure your dataset is in `dataset/` with one subfolder per person (e.g. `dataset/Amine/`, `dataset/Outmane/`).
3. Run all cells. The notebook will:
   - Load and augment data (train/validation split).
   - Build VGG19 (frozen) + custom head.
   - Train and save the model to `model/vgg19_face_model.h5`.

### 4. Run real-time recognition

After training, run:

```bash
python realtime_recognition.py
```

- Uses the default webcam (camera index `0`).
- Detects faces, runs them through the trained VGG19 model, and shows the predicted name and a bounding box.
- Press **Q** to quit.

---

## Dataset Format

- **Path:** `dataset/<PersonName>/`
- **Content:** Images of that person’s face (e.g. `.jpg`, `.png`, `.jpeg`).
- **Naming:** Any valid image filename; the script uses folder names as class labels.

The model learns one class per subfolder; class names are taken from the sorted list of folder names.

---

## Model Details (VGG19 Transfer Learning)

| Component        | Description |
|-----------------|-------------|
| Base model      | VGG19, ImageNet weights, `include_top=False`, input `(224, 224, 3)` |
| Base training   | All VGG19 layers are **frozen** (`trainable=False`) |
| Custom head     | Global MaxPooling2D → Flatten → Dense(128, ReLU) → Dense(num_classes, Softmax) |
| Preprocessing   | `tensorflow.keras.applications.vgg19.preprocess_input` |
| Output          | Probability distribution over the persons in `dataset/` |

Training in the notebook uses `ImageDataGenerator` with augmentation (rotation, shifts, zoom, horizontal flip, brightness) and a validation split (e.g. 80% train / 20% validation).

---

## Scripts Summary

| Script / file           | Role |
|-------------------------|------|
| `save_script.py`        | Capture 60 face images for one person into `dataset/<Name>/`. |
| `augment.py`            | Augment images in `dataset/<folder_name>/`. |
| `train_model.ipynb`     | Train VGG19-based classifier and save `model/vgg19_face_model.h5`. |
| `realtime_recognition.py`| Load model and run real-time face recognition from webcam. |

---

## Notes

- **Camera:** `realtime_recognition.py` uses `cv2.VideoCapture(0)`. Change `0` if your webcam has another index.
- **Model path:** The script expects the model at `model/vgg19_face_model.h5`. Create the `model/` folder and train via the notebook if it is missing.
- **Performance:** For more identities or higher accuracy, consider adding more images per person and/or tuning epochs and augmentation in the notebook.

---

## License

This project is for educational purposes. Use and modify as needed for your assignments and experiments, created by Mohamed Amine Rezoum
